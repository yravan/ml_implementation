
# =============================================================================
# ImageNet ResNet-18 — DDP multi-GPU training
# =============================================================================
# Launch with torchrun:
#   torchrun --nproc_per_node=4 -m experiment --config configs/imagenet_resnet50_ddp.yaml
#
# Or override GPU count at launch time (config is GPU-count agnostic):
#   torchrun --nproc_per_node=8 -m experiment --config configs/imagenet_resnet18_ddp.yaml

name: imagenet-resnet50-ddp
dataset: imagenet
data_dir: ~/orcd/datasets/imagenet/images_complete/ilsvrc
backend: pytorch
model: resnet50
model_args:
  num_classes: 1000

# ── Training ─────────────────────────────────────────────────────
# NOTE: batch_size is PER GPU. Effective batch = batch_size * nproc_per_node
# With 4 GPUs and batch_size 256: effective batch = 1024
epochs: 200
batch_size: 1024
lr: 4e-3
optimizer: adamw
weight_decay: 0.05
scheduler: cosine
label_smoothing: 0.1
warmup_epochs: 10

# ── DDP ──────────────────────────────────────────────────────────
ddp: true
ddp_backend: nccl               # nccl for GPU, gloo for CPU/fallback
ddp_find_unused: false
ddp_gradient_as_bucket: true

# ── Performance ──────────────────────────────────────────────────
num_workers: 8
pin_memory: true
amp: true
compile: true
compile_mode: max-autotune
compile_cache_dir: /tmp/torch_compile_cache  # persists across restarts within same job
cudnn_benchmark: true
ffcv: true
beton_dir: /tmp/ffcv_cache          # fast local NVMe
beton_source_dir: ~/orcd/pool/ffcv_cache  # pre-built betons copied to beton_dir at start

# ── Logging ──────────────────────────────────────────────────────
logger: wandb
wandb_project: imagenet
metrics: [top1, top5]
log_interval: 100
save_every: 10
